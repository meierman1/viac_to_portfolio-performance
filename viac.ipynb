{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "899e5b53-7316-4ed0-abbe-1bd1fd8d24c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "filename = Path('test.pdf')\n",
    "url = 'https://app.viac.ch/files/document/21V-L0F-58I/content/21V-L0F-58I.pdf'\n",
    "response = requests.get(url)\n",
    "filename.write_bytes(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5593fbea-a4f4-44dd-aba0-c2ece6f01f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import pymupdf  # PyMuPDF\n",
    " \n",
    "\n",
    "\n",
    "# Define a function to extract shares and exchange rate from a PDF file\n",
    "def extract_shares_and_exchange_rate(document_number):\n",
    "    shares = ''\n",
    "    exchange_rate = ''\n",
    "    isin = ''\n",
    "    \n",
    "\n",
    "    # Find the PDF file that contains the document number as a substring\n",
    "    pdf_folder = 'pdfs'\n",
    "    pdf_files = [f for f in os.listdir(pdf_folder) if document_number in f]\n",
    "\n",
    "    if not pdf_files:\n",
    "        raise FileNotFoundError(f\"No PDF file found containing document number {document_number}\")\n",
    "\n",
    "    pdf_path = os.path.join(pdf_folder, pdf_files[0])\n",
    "\n",
    "    # Open the PDF file\n",
    "    pdf_document = pymupdf.open(pdf_path)\n",
    "\n",
    "    # Iterate through each page\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "\n",
    "        # Search for shares value\n",
    "        shares_match = re.search(r'(?:Kauf|Buy|Verkauf|Sell)\\n(\\d+\\.\\d+)', text)\n",
    "        if shares_match:\n",
    "            shares = shares_match.group(1)\n",
    "        if len(shares)<2:\n",
    "            print(f\"Error in transaction {document_number}. File exists but could not find number of shares!\")\n",
    "        \n",
    "\n",
    "        currency = \"\"\n",
    "        # Search for exchange rate value\n",
    "        exchange_rate_match = re.search(r'(?:Exchange rate|Umrechnungskurs) [A-Z]{3}/[A-Z]{3} (\\d+\\.\\d+)\\n', text)\n",
    "        if exchange_rate_match:\n",
    "            exchange_rate = exchange_rate_match.group(1)\n",
    "            exchange_rate = \"{:3.8f}\".format(1/float(exchange_rate)) # take the inverse\n",
    "            \n",
    "            currency_match = re.search(r'(?:Exchange rate|Umrechnungskurs) [A-Z]{3}/([A-Z]{3})\\s*\\d+\\.\\d+', text, re.DOTALL)\n",
    "            if currency_match:\n",
    "                currency = currency_match.group(1)\n",
    "            \n",
    "            \n",
    "            \n",
    "        # Search for ISIN\n",
    "        isin_match = re.search(r'ISIN.{0,8}([A-Z0-9]{12})', text, re.DOTALL)\n",
    "        if isin_match:\n",
    "            isin = isin_match.group(1)\n",
    "        \n",
    "\n",
    "    pdf_document.close()\n",
    "\n",
    "    \n",
    "    return shares, exchange_rate, isin, currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98450467-b450-4823-a4eb-c3bdf0503f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files have been generated for each account.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "last_ex_rate = {}\n",
    "last_curr = {}\n",
    "\n",
    "def process_transactions(account_id, transactions, securities):\n",
    "    # Prepare the CSV file names\n",
    "    portfolio_csv_file_name = f\"{account_id}_PortfolioTransaction.csv\"\n",
    "    account_csv_file_name = f\"{account_id}_AccountTransaction.csv\"\n",
    "    \n",
    "    # Define fieldnames for each CSV file\n",
    "    fieldnames = ['Date', 'Type', 'Value', 'Security Name', 'Transaction Currency', 'Shares', 'Exchange Rate', 'Note']\n",
    "    \n",
    "    # Open the CSV files for writing\n",
    "    with open(portfolio_csv_file_name, 'w', newline='') as portfolio_csvfile, open(account_csv_file_name, 'w', newline='') as account_csvfile:\n",
    "        portfolio_writer = csv.DictWriter(portfolio_csvfile, fieldnames=fieldnames)\n",
    "        account_writer = csv.DictWriter(account_csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        # Write the headers\n",
    "        portfolio_writer.writeheader()\n",
    "        account_writer.writeheader()\n",
    "        \n",
    "        # Track dividend cancellations to ignore corresponding dividends\n",
    "        dividend_cancellations = []\n",
    "        \n",
    "        # First pass: build the list of dividend cancellations\n",
    "        for transaction in transactions:\n",
    "            if transaction['type'] == 'DIVIDEND_CANCELLATION':\n",
    "                dividend_cancellations.append(transaction)\n",
    "        \n",
    "        # Second pass: process transactions and write to the appropriate CSV\n",
    "        for transaction in transactions[::-1]:\n",
    "            if transaction['type'] == 'DIVIDEND_CANCELLATION':\n",
    "                continue\n",
    "            \n",
    "            if transaction['type'] == 'DIVIDEND':\n",
    "                # Check if there is a matching DIVIDEND_CANCELLATION within 30 days\n",
    "                cancel = False\n",
    "                for cancel_transaction in dividend_cancellations:\n",
    "                    cancel_date = datetime.strptime(cancel_transaction['valueDate'], '%Y-%m-%d')\n",
    "                    transaction_date = datetime.strptime(transaction['valueDate'], '%Y-%m-%d')\n",
    "                    if (cancel_transaction['amountInChf'] == transaction['amountInChf'] and\n",
    "                        abs((transaction_date - cancel_date).days) <= 30):\n",
    "                        cancel = True\n",
    "                        break\n",
    "                if cancel:\n",
    "                    continue\n",
    "            \n",
    "            row = {\n",
    "                'Date': transaction['valueDate'],\n",
    "                'Type': '',\n",
    "                'Value': round(abs(transaction['amountInChf']), 8),\n",
    "                'Security Name': '',\n",
    "                'Transaction Currency': 'CHF',\n",
    "                'Shares': '',\n",
    "                'Exchange Rate': '',\n",
    "                'Note': ''\n",
    "            }\n",
    "            \n",
    "            if transaction['type'] == 'CONTRIBUTION':\n",
    "                row['Type'] = 'Deposit'\n",
    "            elif transaction['type'] == 'DIVIDEND':\n",
    "                row['Type'] = 'Dividend'\n",
    "                row['Security Name'] = transaction.get('description', '')\n",
    "                if last_ex_rate[row['Security Name']] != '': # foreign currency divident, not working, make it interest\n",
    "                    row['Type'] = 'Interest'\n",
    "                    row['Note'] = 'Dividend from \"{}\" original currency: {}, est. exchange rate: {}, CHF amount {}'.format(row['Security Name'], \n",
    "                                                                                                                           last_curr[row['Security Name']],\n",
    "                                                                                                                           last_ex_rate[row['Security Name']], \n",
    "                                                                                                                           row['Value'])\n",
    "                    row['Security Name'] = ''\n",
    "                    # row['Gross Amount'] = row['Value']\n",
    "                    # row['Gross Amount'] = row['Value']*float(row['Exchange Rate'])\n",
    "                    # row['Value'] = row['Value']*float(row['Exchange Rate'])\n",
    "                    # row['Value'] = row['Value']\n",
    "                    # row['Transaction Currency'] = last_curr[row['Security Name']]\n",
    "                    # row['Transaction Currency'] = 'CHF'\n",
    "                    # row['Currency Gross Amount'] = last_curr[row['Security Name']]\n",
    "                \n",
    "            elif transaction['type'] in ['TRADE_SELL', 'TRADE_BUY']:\n",
    "                row['Security Name'] = transaction.get('description', '')\n",
    "                try:\n",
    "                    shares, exchange_rate, isin, currency = extract_shares_and_exchange_rate(transaction['documentNumber'])\n",
    "                    if isin not in securities:\n",
    "                        securities[isin] = (row['Security Name'], currency)\n",
    "                    row['Shares'] = shares\n",
    "                    row['Exchange Rate'] = exchange_rate\n",
    "                    last_ex_rate[row['Security Name']] = exchange_rate\n",
    "                    last_curr[row['Security Name']] = currency\n",
    "                except FileNotFoundError as e:\n",
    "                    print(f\"Warning: PDF not found for transaction:\")\n",
    "                    print(f\"{transaction['type'].split('_')[1]} {transaction['valueDate']} {transaction.get('description', '')} of CHF {transaction['amountInChf']}\")\n",
    "                if transaction['type'] == 'TRADE_SELL':\n",
    "                    row['Type'] = 'Sell'\n",
    "                else: # transaction['type'] == 'TRADE_BUY':\n",
    "                    row['Type'] = 'Buy'\n",
    "                \n",
    "            elif transaction['type'] == 'INTEREST':\n",
    "                row['Type'] = 'Interest'\n",
    "            elif transaction['type'] == 'FEE_CHARGE':\n",
    "                row['Type'] = 'Fees'\n",
    "            elif transaction['type'] != 'DIVIDEND_CANCELLATION':\n",
    "                print(\"Warning: Unknown Transaction type {}. Transaction ignored\".format(transaction['type']))\n",
    "                \n",
    "            \n",
    "            # Write to the appropriate CSV file\n",
    "            if transaction['type'] in ['TRADE_SELL', 'TRADE_BUY']:\n",
    "                portfolio_writer.writerow(row)\n",
    "            else:\n",
    "                account_writer.writerow(row)\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open('transactions.json', 'r') as file:\n",
    "    transactions = json.load(file)\n",
    "                \n",
    "# Process each account in the JSON data\n",
    "securities = {}\n",
    "for account_id, transactions in transactions['transactions'].items():\n",
    "    process_transactions(account_id, transactions, securities)\n",
    "    \n",
    "with open(\"securities.csv\", mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header\n",
    "    writer.writerow([\"ISIN\", \"Security Name\", \"Currency\"])\n",
    "    # Write the data\n",
    "    for key, value in securities.items():\n",
    "        writer.writerow([key, value[0], value[1]])\n",
    "\n",
    "print(\"CSV files have been generated for each account.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045e5e04-6121-4294-b541-418a6bb08868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20f66e1-1d5e-482d-87a3-2c777caca0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pymupdf  # PyMuPDF\n",
    "\n",
    "def remove_duplicates_and_concatenate_pdfs(folder_path):\n",
    "    # Get list of all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    # Filter out only PDF files\n",
    "    pdf_files = [f for f in files if f.endswith('.pdf')]\n",
    "    \n",
    "    # Dictionary to keep track of unique files\n",
    "    unique_files = {}\n",
    "    \n",
    "    # Regular expression to match duplicate files\n",
    "    duplicate_pattern = re.compile(r'\\((\\d+)\\)\\.pdf$')\n",
    "    \n",
    "    for pdf in pdf_files:\n",
    "        # Remove the duplicate pattern from the filename\n",
    "        base_name = re.sub(duplicate_pattern, '.pdf', pdf)\n",
    "        \n",
    "        # If the base name is not in the dictionary, add it\n",
    "        if base_name not in unique_files:\n",
    "            unique_files[base_name] = pdf\n",
    "    \n",
    "    # List to store the paths of unique PDF files\n",
    "    unique_pdf_paths = [os.path.join(folder_path, unique_files[base_name]) for base_name in unique_files]\n",
    "\n",
    "    \n",
    "    # Create a new PDF document to concatenate all PDFs\n",
    "    output_pdf = pymupdf.open()\n",
    "    \n",
    "    for pdf_path in unique_pdf_paths:\n",
    "        # Open each PDF file\n",
    "        input_pdf = pymupdf.open(pdf_path)\n",
    "        \n",
    "        # Append each page to the output PDF\n",
    "        for page_num in range(len(input_pdf)):\n",
    "            output_pdf.insert_pdf(input_pdf, from_page=page_num, to_page=page_num)\n",
    "    \n",
    "    # Save the concatenated PDF\n",
    "    output_pdf.save(os.path.join(folder_path, 'concatenated_output.pdf'))\n",
    "    \n",
    "    print(f\"Concatenated PDF saved as 'concatenated_output3.pdf' in {folder_path}\")\n",
    "    return unique_pdf_paths\n",
    "\n",
    "# Folder path containing the PDF files\n",
    "folder_path = r\"C:\\Users\\Manuel Meier\\Downloads\\viac1transactions\"\n",
    "\n",
    "# Call the function to remove duplicates and concatenate PDFs\n",
    "remove_duplicates_and_concatenate_pdfs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcfc6dd9-59cb-43fc-b6e4-44bbb0c4852e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manuel Meier\\Downloads\\viac1transactions\\21V-KCE-D9V.pdf\n"
     ]
    }
   ],
   "source": [
    "# Regular expression to match duplicate files\n",
    "duplicate_pattern = re.compile(r'\\((\\d+)\\)\\.pdf$')\n",
    "\n",
    "base_name = re.sub(duplicate_pattern, '.pdf', 'C:\\\\Users\\\\Manuel Meier\\\\Downloads\\\\viac1transactions\\\\21V-KCE-D9V(2).pdf')\n",
    "print(base_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876f36d4-147e-4df9-8c98-f32d3c61ec54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e50d6b26-f4b8-4418-a64b-68f57c0bdc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mWarning: CH0110869143 is already in the portfolio but name is CH0033782431 but viac calls it UBS SPI Extra. This may require you to select the security manually when importing transactions.\u001b[0m\n",
      "CH0033782431 UBS SMI ok\n",
      "IE00B5BMR087 iShares Core S&P500 ok\n",
      "IE00B1FZSF77 iShares US Property Yield ok\n",
      "LU0439730705 UBS Global Quality Dividend ok\n",
      "CH0036599816 UBS Real Estate CH ok\n",
      "CH0032912732 UBS ETF SLI ok\n",
      "CH0032044684 CSIF Europe ex CH Real Estate ok\n",
      "CH0037606552 UBS Europe ex CH (old) ok\n",
      "CH0032044791 CSIF Asia Real Estate ok\n",
      "CH0214967314 CSIF World ex CH Small Cap - Pension Fund ok\n",
      "CH0030849647 CSIF Japan ok\n",
      "CH0030849654 UBS Pacific ex Japan (old) ok\n",
      "CH0032400639 CSIF World ex CH - Pension Fund ok\n",
      "CH0217837456 CSIF Real Estate World ex CH - Pension Fund (old) ok\n",
      "CH0017844686 UBS Emerging Markets (old) ok\n",
      "CH0030849613 UBS Canada ok\n",
      "CH0030849712 CSIF US - Pension Fund ok\n",
      "CH0357515474 UBS Japan - Pension Fund ok\n",
      "CH0429081620 CSIF World ex CH - Pension Fund Plus ok\n",
      "CH0209106761 CSIF Gold ok\n",
      "CH0214968353 CSIF World ex CH Small Cap hedged - Pension Fund ok\n",
      "CH0429081638 CSIF World ex CH hedged - Pension Fund Plus ok\n",
      "CH0597394516 UBS SPI ESG ok\n",
      "IE00B53SZB19 iShares Nasdaq 100 ok\n",
      "CH0215804714 Swisscanto SMI (SPI 20) ok\n",
      "CH0117044948 Swisscanto World ex CH - IPF ok\n"
     ]
    }
   ],
   "source": [
    "# modify securities\n",
    "\n",
    "\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Read securities.csv and store the data in a dictionary\n",
    "securities_csv = 'securities.csv'\n",
    "securities_data = {}\n",
    "\n",
    "with open(securities_csv, mode='r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    for row in csv_reader:\n",
    "        isin = row['ISIN']\n",
    "        name = row['Security Name']\n",
    "        currency = row['Currency']\n",
    "        securities_data[isin] = {'name': name, 'currency': currency}\n",
    "\n",
    "# Parse test_portfolio.xml\n",
    "portfolio_xml = 'test_portfolio.xml'\n",
    "portfolio_tree = ET.parse(portfolio_xml)\n",
    "portfolio_root = portfolio_tree.getroot()\n",
    "\n",
    "# Function to find security by ISIN in the XML tree\n",
    "def find_security_by_isin(root, isin):\n",
    "    for security in root.findall('.//security'):\n",
    "        if security.find('isin') is not None and security.find('isin').text == isin:\n",
    "            return security\n",
    "    return None\n",
    "\n",
    "# Check each security from the CSV in the portfolio XML\n",
    "for isin, data in securities_data.items():\n",
    "    name_csv = data['name']\n",
    "    currency_csv = data['currency']\n",
    "    \n",
    "    security_in_portfolio = find_security_by_isin(portfolio_root, isin)\n",
    "    \n",
    "    if security_in_portfolio is not None:\n",
    "        name_portfolio = security_in_portfolio.find('name').text\n",
    "        if name_csv == name_portfolio:\n",
    "            print(f\"{isin} {name_csv} ok\")\n",
    "        else:\n",
    "            print(f\"\\033[1;31mWarning: {isin} is already in the portfolio but name is {name_portfolio} but viac calls it {name_csv}. This may require you to select the security manually when importing transactions.\\033[0m\")\n",
    "    else:\n",
    "        # If not found in portfolio, check in pp_all_securities.xml\n",
    "        all_securities_xml = 'data/pp_all_viac_securities.xml'\n",
    "        all_securities_tree = ET.parse(all_securities_xml)\n",
    "        all_securities_root = all_securities_tree.getroot()\n",
    "        \n",
    "        security_in_all_securities = find_security_by_isin(all_securities_root, isin)\n",
    "        \n",
    "        if security_in_all_securities is not None:\n",
    "            # Copy the security to the portfolio XML\n",
    "            portfolio_root.find('.//securities').append(security_in_all_securities)\n",
    "            print(f\"added {isin} {name_csv} to portfolio\")\n",
    "            \n",
    "            # Save the updated portfolio XML\n",
    "            portfolio_tree.write(portfolio_xml)\n",
    "        else:\n",
    "            print(f\"\\033[1;31mError: {isin} {name_csv} {currency_csv} is not in our database, please add it manually to the securities before adding transactions. You may also send this info to us through github so that we can add it to the list.\\033[0m\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
